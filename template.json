{
  "name": "CINDERGRACE ComfyUI + Toolkit",
  "description": "Minimal ComfyUI with dynamic custom nodes via Cindergrace Toolkit. Auto-updates on start. Supports Wan 2.2, Flux, LTX-Video.",
  "dockerImage": "ghcr.io/goettemar/cindergrace-comfyui-runpod:latest",
  "containerDiskInGb": 30,
  "volumeInGb": 0,
  "volumeMountPath": "/workspace",
  "ports": "8188/http,7861/http",
  "env": [
    {
      "key": "SKIP_UPDATE",
      "value": "false"
    },
    {
      "key": "DISABLE_TOOLKIT",
      "value": "false"
    }
  ],
  "startCommand": "/opt/cindergrace/start.sh",
  "readme": "# CINDERGRACE ComfyUI + Toolkit\n\nMinimal ComfyUI image with dynamic custom node installation via Cindergrace Toolkit.\n\n## Features\n\n- **CUDA 12.8** - Supports RTX 50xx (Blackwell), 40xx, A100, H100\n- **Auto-Update** - ComfyUI, Toolkit, and nodes update on every start\n- **Dynamic Custom Nodes** - Nodes installed from config, no image rebuild needed\n- **Workflow Sync** - Workflows synced automatically from Toolkit\n- **Model Management** - Download and manage models via browser UI\n\n## Services\n\n| Service | URL | Port |\n|---------|-----|------|\n| ComfyUI | `https://<POD_ID>-8188.proxy.runpod.net` | 8188 |\n| Toolkit | `https://<POD_ID>-7861.proxy.runpod.net` | 7861 |\n\n## Quick Start\n\n1. **Create Network Volume** (100-150 GB) for models\n2. **Deploy pod** with this template\n3. **Attach Network Volume** at `/workspace`\n4. **Open Toolkit** to download models\n5. **Use ComfyUI** for generation\n\n## Environment Variables\n\n- `SKIP_UPDATE=true` - Skip auto-update (faster startup)\n- `DISABLE_TOOLKIT=true` - Don't start Toolkit\n\n## Startup Flow\n\n```\n[1/6] Clone/Update Cindergrace Toolkit\n[2/6] Update ComfyUI\n[3/6] Sync Custom Nodes from config\n[4/6] Sync Workflows\n[5/6] Link models from Network Volume\n[6/6] Start services\n```\n\n## Network Volume Structure\n\n```\n/workspace/\n├── models/              # Your models (persistent)\n├── input/               # Upload images (persistent)\n├── output/              # Generated files (persistent)\n├── ComfyUI/             # Auto-updated\n└── cindergrace_toolkit/ # Auto-cloned\n```\n\n## GPU Recommendations\n\n- **RTX 4090/5090** (24-32GB): WAN FP8, Flux\n- **A100 40GB+**: Full BF16 models\n\n## Links\n\n- [Toolkit](https://github.com/goettemar/cindergrace_toolkit)\n- [Docker Image](https://github.com/goettemar/cindergrace-comfyui-runpod)\n",
  "category": "AI / ML",
  "minVcpu": 4,
  "minMemoryInGb": 32,
  "minGpuCount": 1,
  "gpuTypes": [
    "NVIDIA RTX 4090",
    "NVIDIA RTX 5090",
    "NVIDIA RTX A5000",
    "NVIDIA RTX A6000",
    "NVIDIA L40",
    "NVIDIA L40S",
    "NVIDIA A100-SXM4-40GB",
    "NVIDIA A100-SXM4-80GB",
    "NVIDIA A100 80GB PCIe"
  ]
}
